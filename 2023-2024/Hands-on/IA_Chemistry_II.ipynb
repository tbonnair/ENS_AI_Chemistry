{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMkJpqRtcdJqYFWmMXqjuYE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Colab link: https://colab.research.google.com/drive/1qVXlMmOlAj-bh-vMcSP8gJcFKYlRWJ5S?usp=sharing.\n","\n","# Scientific context of the problem\n","\n","The problem is presented at https://challengedata.ens.fr/challenges/122 and proposed by the chemistry department of ENS (Pablo MAS and Rodolphe Vuilleumier).\n","We propose in this notebook to build a simple algorithm based on these data using decision trees and random forest."],"metadata":{"id":"RtFIen19WOu1"}},{"cell_type":"markdown","source":["# The data\n","\n","The dataset is made of the SMILES (simplified molecular-input line-entry system) text description of 4400 molecules. It is possible to work directly with this format but it is also possible to convert SMILES into molecular graphs or molecular fingerprints.\n","Fingerprints are binary vectors that capture the presence or absence of specific chemical features, such as functional groups, atom types, bonds, or molecular properties. It is the most common way to encode the chemical information contained in a molecule and that is the approach used in the introduction notebook to get the baseline score.\n","\n","1. What is the machine learning family this problem is about? What is the nature of the input data?\n","\n","2. Enumerate some methods that could be used for such a task."],"metadata":{"id":"cHEsjsf4DMq8"}},{"cell_type":"markdown","source":["# Prerequisites\n","\n","3. Import the necessary packages, in particular, we will use:\n","> * [`matplotlib`](https://matplotlib.org/) for data visualisation and plots,\n","> * [`numpy`](https://numpy.org/) for standard numerical operations and algebra,\n","> * [`pandas`](https://pandas.pydata.org/) for data analysis,\n","> * [`scikit-learn`](https://scikit-learn.org/stable/) for ML algorithms and related functions used for model selection or data pre-processing.\n","> * [`rdkit`](https://www.rdkit.org/docs/GettingStartedInPython.html) to transform the text descriptions into fingerprints (vector representations).\n"],"metadata":{"id":"5tb5ItMEVYEI"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xj4fjZv1VXRx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697624162474,"user_tz":-120,"elapsed":16217,"user":{"displayName":"Tony","userId":"03188807958140873473"}},"outputId":"679a34e1-69a0-4285-8048-0d84a4f376f4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rdkit\n","  Downloading rdkit-2023.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.7/29.7 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n","Installing collected packages: rdkit\n","Successfully installed rdkit-2023.3.3\n"]}],"source":["import pandas                       # For data management\n","import matplotlib.pyplot as plt     # For plotting\n","import matplotlib as mpl            # For plotting setup\n","import numpy as np                  # For numerical calculations\n","import sklearn                      # Machine learning library\n","from sklearn import model_selection\n","from sklearn import metrics\n","\n","!pip install rdkit\n","\n","# For fingerprints\n","import rdkit\n","from rdkit import Chem\n","from rdkit.Chem import AllChem\n","\n","# Formatting the plots\n","plt.rcParams['figure.figsize'] = [6,6]\n","plt.rcParams['font.size'] = 18\n","plt.rcParams['font.weight'] = 'normal'\n","plt.style.use('default')\n","mpl.rcParams['mathtext.fontset'] = 'cm'\n","mpl.rcParams['mathtext.rm'] = 'serif'\n","mpl.rcParams['font.size'] = 22\n","mpl.rcParams['axes.formatter.limits'] = (-6, 6)\n","mpl.rcParams['axes.formatter.use_mathtext'] = True\n","mpl.rcParams['font.family'] = 'STIXGeneral'\n","mpl.rcParams['mathtext.rm'] = 'Bitstream Vera Sans'\n","mpl.rcParams['mathtext.it'] = 'Bitstream Vera Sans:italic'\n","mpl.rcParams['mathtext.bf'] = 'Bitstream Vera Sans:bold'\n","mpl.rcParams['xtick.minor.visible'] = True\n","mpl.rcParams['ytick.minor.visible'] = True"]},{"cell_type":"markdown","source":["4. To download the training dataset, you can get it from [my Github](https://github.com/tbonnair/Machine-Learning-Principles-with-Applications-in-Physics) or directly from the [ChallengeData website](https://challengedata.ens.fr/challenges/122) by creating an account."],"metadata":{"id":"sqcmy56HV-Jv"}},{"cell_type":"code","source":["!git clone https://github.com/tbonnair/ENS_AI_Chemistry.git/"],"metadata":{"id":"4DApyDnLWA9K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1697624169055,"user_tz":-120,"elapsed":3944,"user":{"displayName":"Tony","userId":"03188807958140873473"}},"outputId":"e0b7d9a1-29fe-43cc-e9fc-ec6259470dda","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'ENS_AI_Chemistry'...\n","remote: Enumerating objects: 27, done.\u001b[K\n","remote: Counting objects: 100% (27/27), done.\u001b[K\n","remote: Compressing objects: 100% (18/18), done.\u001b[K\n","remote: Total 27 (delta 3), reused 26 (delta 2), pack-reused 0\u001b[K\n","Receiving objects: 100% (27/27), 9.55 MiB | 7.06 MiB/s, done.\n","Resolving deltas: 100% (3/3), done.\n"]}]},{"cell_type":"markdown","source":["# Loading, exploring, and preparing the data\n","\n","5. Load the data ($X_\\mathrm{train}$ and $y_\\mathrm{train}$) using the `pandas` package."],"metadata":{"id":"HpPQ4X47WDZg"}},{"cell_type":"code","source":["Xpath = 'ENS_AI_Chemistry/Hands-on/Data/X_train.csv'\n","ypath = 'ENS_AI_Chemistry/Hands-on/Data/y_train.csv'\n","X_dataset = pandas.read_csv(Xpath, index_col=0)\n","y_dataset = pandas.read_csv(ypath, index_col=0)"],"metadata":{"id":"ShFaJmILWSbd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6. Explore the data (how many molecules are there, how the data look like, etc.) using the `pandas` library. To do so, you can use the .head() and .info() functions.\n"],"metadata":{"id":"FqpvhFw5WhNh"}},{"cell_type":"code","source":["# Your code to explore the dataset"],"metadata":{"id":"kXzcNvSuWw5C"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can also have a look at the distribution of pIC50 in the training set, the quantity we aim to predict based on the text description."],"metadata":{"id":"by3NCLafHdcU"}},{"cell_type":"markdown","source":["8. Using the rdkit package, we will first transform the data from their text (SMILES) description into vectors using 512 bits and a radius of 3. For an explanation of the Morgan fingerprints, you can have a look [here](https://www.rdkit.org/UGM/2012/Landrum_RDKit_UGM.Fingerprints.Final.pptx.pdf)."],"metadata":{"id":"VDCq6xbmGsf1"}},{"cell_type":"code","source":["# Convert Mol to fingerprints\n","train_mols = [AllChem.MolFromSmiles(smile) for smile in X_dataset['smiles']]\n","nbits = 512   # For the benchmark a number of 2048 bits was used\n","rad = 3\n","train_fps = np.array([AllChem.GetMorganFingerprintAsBitVect(mol, radius=rad, nBits=nbits) for mol in train_mols])"],"metadata":{"id":"VfN_VulyGlDp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_fps)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rW9Ho4fcG_qE","executionInfo":{"status":"ok","timestamp":1697624190490,"user_tz":-120,"elapsed":5,"user":{"displayName":"Tony","userId":"03188807958140873473"}},"outputId":"01f24dd1-53ff-4d9c-efc8-1c61e73be3d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 1 0 ... 0 0 0]\n"," [0 0 0 ... 0 0 1]\n"," [0 0 0 ... 0 0 1]\n"," ...\n"," [0 0 0 ... 0 0 0]\n"," [1 0 0 ... 0 0 0]\n"," [1 0 0 ... 0 0 0]]\n"]}]},{"cell_type":"markdown","source":["The dataset is now a vector composed of 4400 vectos of one and zero of size 1024. A one means that there is a specific feature present in the SMILE description, while a 0 means it is not. These are the data we'll use in this notebook."],"metadata":{"id":"kwbNvtBQHF1M"}},{"cell_type":"markdown","source":["8. Arange the data into a feature matrix $\\boldsymbol{X}$ and a target vector $\\boldsymbol{y}$. Then, prepare the dataset and split it into 80% training and 20% validation using the scikit-learn [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function."],"metadata":{"id":"uA8K330XXnul"}},{"cell_type":"code","source":["# Your code to split the dataset"],"metadata":{"id":"hB932NvnY2CG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now the data are ready to be used for learning!"],"metadata":{"id":"x-CrkLpVHWlr"}},{"cell_type":"markdown","source":["# A first model: decision tree\n","\n","Now the data are ready to be used for training, let us build a first model: a decision tree.\n","\n","9. Using the scikit-learn documentation, find how to fit a Decision Tree with a maximum depth of 15 and using the absolute error on the training dataset."],"metadata":{"id":"CjEIkAXbcnML"}},{"cell_type":"code","source":["# Your code to define and train a decision tree"],"metadata":{"id":"3owrpRHtdITu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["10. Test your model on the validation dataset and look at the obtained score."],"metadata":{"id":"BhD_Tun_eZuH"}},{"cell_type":"code","source":["# Your code to test your model on the validation dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2CbievL9eZf8","executionInfo":{"status":"ok","timestamp":1697624213964,"user_tz":-120,"elapsed":339,"user":{"displayName":"Tony","userId":"03188807958140873473"}},"outputId":"78aa1eec-fe52-4c86-b668-6406d30af3b4","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.8092525464110052\n"]}]},{"cell_type":"markdown","source":["11. Tune the hyperparameter of the maximum depth. To this end, you can use the validation set we have prepared at the beginning. Find the hyperparameter having the best score on this set with depth in the range [1, 30]."],"metadata":{"id":"4IVVeODoeuud"}},{"cell_type":"code","source":["# Your code to investigate hyperparameters"],"metadata":{"id":"EMd2tnU3eufh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["12. Intepret the evolution of the validation score when varying the maximum depth: how does the validation error behaves and why? (To help you, you can also store and visualise the evolution of the training error in addition to validation error.)"],"metadata":{"id":"vU_Y_y5WjLCw"}},{"cell_type":"markdown","source":["# Improving the model with more trees: random forest\n","\n","13. Remind the principle behind random forests.\n","\n","\n","14. Using the scikit-learn documentation, fit a random forest to the training data with a number of trees of 20 and a maximum depth of 15. Compare this setup with our first decision tree."],"metadata":{"id":"k6ErNvwgg7y7"}},{"cell_type":"code","source":["# Your code to define and train a random forest"],"metadata":{"id":"zymb004tlIJV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["15. Repeat the hyperparameter tuning for tuning the number of trees in [1, 50] at fixed maximum depth = 15 to find the best random forest model for our data."],"metadata":{"id":"tQs1FtY7k_Eb"}},{"cell_type":"code","source":["# Your code to check the impact of the number of trees"],"metadata":{"id":"5K8BxGdYpJLN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["16. Does the curve showing the evolution of the test error look the same as previously with the decision tree depth? Why?"],"metadata":{"id":"YUqZ_GRTx32Z"}},{"cell_type":"markdown","source":["# Going further\n","\n","Now it's your turn to go further and try to beat the benchmark proposed by Pablo. He obtained a MAE of 0.5388 on the test set (that you have not access to, it is hosted on the website) using 2048 bits for the fingerprints and a random forest. For this, you can try to finetune the hyperparameters, to build new models (boosting, neural networks, etc.). The goal is that you learn how to build and compare models, recognise overfitting, etc. and orally present in January the results you obtained, and how you obtained it (the methodology you followed, the papers you were inspired by, etc.)"],"metadata":{"id":"tk133qax5N0n"}},{"cell_type":"markdown","source":["## Randomized search for hyperparameter tuning\n","In our examples, we always focus on one hyperparameter at a time. In fact, using scikit-learn you can specify several ranges for your hyperparameters and test them randomly to find the association of parameters using randomized search or grid search cross-validation. Randomized search is more efficient numerically but is not leading you to the best possible set of parameters, while grid search consists in an exhaustive search in your pre-defined ranges for parameters. Here we illustrate it with randomized search."],"metadata":{"id":"dtqfbpt5U8fG"}},{"cell_type":"code","source":["from sklearn.model_selection import RandomizedSearchCV\n","\n","# define range of values for each hyperparameter\n","hyperparameters_range = [{\n","        \"n_estimators\": [1, 5, 10, 20, 40],       # Number of trees\n","        \"max_features\": [0.5, 1.0, \"sqrt\", \"log2\"],  # Proportion of the features used for training you RFs\n","        \"max_depth\": [5, 10, 15, 20],  # Maximum depth of the trees trained in RFs\n","    }]\n","\n","# Create a base model\n","RF = RandomForestRegressor(n_estimators=20, max_depth=15, n_jobs=-1)\n","\n","# Random search with cross validation\n","RF_CV = RandomizedSearchCV(\n","    RF, param_distributions=hyperparameters_range, cv=5)\n","\n","# Fit the search\n","RF_CV.fit(X_train, np.array(y_train).squeeze())"],"metadata":{"id":"26KLjHfMtnWZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can now select the best model and test it."],"metadata":{"id":"TTWduVq1xKTZ"}},{"cell_type":"code","source":["print(RF_CV.best_params_)         # Prints the best parameters\n","RF_best = RF_CV.best_estimator_   # Select the best model\n","RF_best.score(X_valid, y_valid)     # Test dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FsOC4p_nw75x","executionInfo":{"status":"ok","timestamp":1697526030297,"user_tz":-120,"elapsed":7,"user":{"displayName":"Tony","userId":"03188807958140873473"}},"outputId":"4eb82d78-3076-49e7-eb38-0b058378750b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'n_estimators': 40, 'max_features': 0.5, 'max_depth': 20}\n"]},{"output_type":"execute_result","data":{"text/plain":["0.5878432612644497"]},"metadata":{},"execution_count":31}]},{"cell_type":"markdown","source":["You could do similarly with the [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) function from scikit-learn to perform grid search cross-validation for tuning your hyperparameters."],"metadata":{"id":"EP-12v-DWDZP"}}]}